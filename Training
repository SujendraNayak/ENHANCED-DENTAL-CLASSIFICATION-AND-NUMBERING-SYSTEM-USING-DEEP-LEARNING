import os
import json 
import numpy as np
import cv2
import mrcnn.utils
import mrcnn.config
import mrcnn.model
import random
from skimage import draw
from skimage.draw import polygon
import matplotlib.pyplot as plt
from mrcnn.utils import Dataset



class ToothDataset(Dataset):

    def load_dataset(self, dataset_dir, split_ratio=0.8, is_train=True):
        """
        Load the dental images and annotations (from JSON).
        Assumes each tooth is a class and annotations contain polygons for each tooth.
        """

        tooth_numbers = [18, 17, 16, 15, 14, 13, 12, 11, 21, 22, 23, 24, 25, 26, 27, 28, 48, 47, 46, 45, 44, 43, 42, 41, 31, 32, 33, 34, 35, 36, 37, 38]
       
        # Add classes (32 teeth + background)
        for tooth_number in tooth_numbers:
            self.add_class("dataset", tooth_number, f"tooth_{tooth_number}")
        
        images_dir = os.path.join(dataset_dir, 'images')
        annotations_dir = os.path.join(dataset_dir, 'annots')

        # Get list of all image filenames (without extensions)
        image_filenames = [f[:-4] for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png'))]

        # Shuffle filenames for random splitting
        random.shuffle(image_filenames)

        # Calculate the split index for 80% train and 20% validation
        split_index = int(len(image_filenames) * split_ratio)

        # Separate into training and validation
        image_filenames = image_filenames[:split_index] if is_train else image_filenames[split_index:]

        # Add images and annotations to the dataset
        for image_id in image_filenames:
            img_path = os.path.join(images_dir, f"{image_id}.jpg")  # Assuming image files are .jpg
            ann_path = os.path.join(annotations_dir, f"{image_id}.json")
            
            # Load the image to get dimensions
            image = cv2.imread(img_path)
            if image is None:
                print(f"Warning: Image not found or unable to read: {img_path}")
                continue  # Skip this image

            height, width = image.shape[:2]  # Get height and width

            # Add to dataset
            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path, height=height, width=width)

            # Print loaded image info
            print(f"Loaded image: {img_path}")
            print(f"Annotation: {ann_path}")

            # Print additional information about the image
            print(f"Image dimensions: {width} x {height}")
           

        # Print total number of images loaded
        print(f"\nTotal images loaded: {len(image_filenames)}")

    def load_mask(self, image_id):
        """Generate instance masks for the given image ID."""
        # Get the annotation path for the given image ID
        image_info = self.image_info[image_id]
        annotation_path = image_info['annotation']

        # Check if the annotation file exists
        if not os.path.exists(annotation_path):
            print(f"Warning: Annotation file not found: {annotation_path}")
            return np.empty((0, image_info['height'], image_info['width'])), np.empty((0,), dtype=np.int32)

        # Load the annotation file
        with open(annotation_path) as f:
            annotations = json.load(f)

        # Initialize lists for masks, class IDs
        masks = []
        class_ids = []

        for region_key, region_data in annotations.items():
            if 'regions' in region_data:
                for region in region_data['regions']:
                    # Extract polygon points for the current tooth
                    shape_attributes = region['shape_attributes']
                    points_x = shape_attributes['all_points_x']
                    points_y = shape_attributes['all_points_y']

                    # Clip polygon points within the image dimensions
                    points_x = np.clip(points_x, 0, image_info['width'] - 1)
                    points_y = np.clip(points_y, 0, image_info['height'] - 1)

                    # Create a binary mask for the current tooth
                    mask = np.zeros((image_info['height'], image_info['width']), dtype=np.uint8)
                    rr, cc = polygon(points_y, points_x)  # Note: points are (x, y), we need (row, col)
                    mask[rr, cc] = 1  # Fill the polygon area with 1
                    masks.append(mask)

                    # Extract and sanitize the tooth number
                    tooth_number = region['region_attributes'].get('Numbers', '0').replace('`', '').strip()
                    tooth_number = int(tooth_number) 
                    class_ids.append(tooth_number) #if tooth_number.isdigit() else 0
        # Ensure masks and class_ids are numpy arrays
        if masks:
            masks = np.stack(masks, axis=-1)  # Shape: (height, width, num_masks)
            class_ids = np.array(class_ids, dtype=np.int32)  # Shape: (num_masks,)
        else:
            masks = np.empty((image_info['height'], image_info['width'], 0), dtype=np.bool_)
            class_ids = np.empty((0,), dtype=np.int32)

        return masks.astype(np.bool_), class_ids
def plot_image_with_masks(image, masks, class_ids, tooth_numbers):
    """
    Plot the image with the corresponding masks and tooth numbers.

    Args:
        image (numpy.ndarray): The original image.
        masks (numpy.ndarray): The masks for the teeth.
        class_ids (numpy.ndarray): The class IDs for each mask.
        tooth_numbers (numpy.ndarray): The tooth numbers for each mask.
    """

    # Debugging Output
    print("Masks shape:", masks.shape)
    print("Class IDs:", class_ids)
    # Create a copy of the image to draw on
    image_with_masks = image.copy()
    
    # Get the number of masks
    num_masks = masks.shape[-1]
    
    # Generate a distinct color for each tooth mask
    np.random.seed(42)  # Ensures colors are consistent across runs
    colors = np.random.randint(0, 255, size=(num_masks, 3), dtype=np.uint8)  # Generate random colors

    for i in range(num_masks):
        # Create a binary mask for the current tooth
        mask = masks[:, :, i]
        
        # Extract the color for this mask
        color = colors[i]
        
        # Apply the color to the mask
        for c in range(3):  # For each channel (R, G, B)
            image_with_masks[:, :, c] = np.where(mask == 1,
                                                  image_with_masks[:, :, c] * 0.5 + color[c] * 0.5,
                                                  image_with_masks[:, :, c])

        # Get the coordinates of the centroid of the mask for placing the text
        y_indices, x_indices = np.where(mask == 1)
        if len(y_indices) > 0 and len(x_indices) > 0:
            centroid_y = int(np.mean(y_indices))
            centroid_x = int(np.mean(x_indices))
            
            # Put the tooth number on the image with increased font size
            cv2.putText(image_with_masks,str(class_ids[i]), (centroid_x, centroid_y), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)  # Increased font size and thickness

    # Plot the original image with masks
    plt.figure(figsize=(10, 10))
    plt.imshow(image_with_masks.astype(np.uint8))
    plt.axis('off')
    plt.title('Image with Tooth Masks and Numbers')

    plt.show()


    # Create dataset instance
dataset = ToothDataset()

# Load the dataset (80% train, 20% validation)
print("Loading training dataset...")
dataset.load_dataset(dataset_dir='Dental_Tooth_Classification', is_train=True)  # For training set
dataset.prepare()

print("\nLoading validation dataset...")
dataset.load_dataset(dataset_dir='Dental_Tooth_Classification', is_train=False)  # For validation set
dataset.prepare()

# Check if datasets are loaded properly
if len(dataset.image_info) == 0:
    raise ValueError("No images found in the dataset. Please check the dataset directory and annotations.")

# Load and process a sample image
image_id = 0  # Replace with a valid image ID that exists in your dataset
if image_id < len(dataset.image_info):
    masks, class_ids = dataset.load_mask(image_id)



    # Load the original image for plotting
    image_info = dataset.image_info[image_id]
    image_path = image_info['path']
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for plotting

    # Call the function to plot the image with masks
    plot_image_with_masks(image, masks, class_ids, tooth_numbers=class_ids)
else:
    print("Invalid image ID provided.")

import tensorflow as tf
from mrcnn.config import Config
from mrcnn.model import MaskRCNN
import os
from mrcnn import visualize


# os.environ["CUDA_VISIBLE_DEVICES"] = "-1"  # Disable GPU if needed

class ToothConfig(Config):
    """Configuration for training on the dental tooth dataset."""
    NAME = "tooth"
    IMAGES_PER_GPU = 1 # Adjust based on your GPU memory
    NUM_CLASSES =1+32 # Background + 32 teeth classes+
    STEPS_PER_EPOCH =100  # Adjust based on your dataset size
    GPU_COUNT = 1  # Change if you have multiple GPUs
    LEARNING_RATE = 0.0001
    BACKBONE = "resnet101" 
    BATCH_SIZE = 2
    GRADIENT_CLIP_NORM = 10
   
     # Backbone model (ResNet50, ResNet101, etc.)



# Create an instance of the configuration
config = ToothConfig()
config.display()  # Display the configuration

# Create the model in training mode
model = MaskRCNN(mode="training", model_dir='./',config=config)

# Path to the COCO weights file
weights_path = 'mask_rcnn_coco.h5'

# Load weights for the model (if you want to start with pre-trained weights)
# You can use COCO weights for better performance
# model.load_weights(weights_path, 
#                    by_name=True, 
#                    exclude=["mrcnn_class_logits", "mrcnn_bbox_fc", "mrcnn_bbox", "mrcnn_mask"])


# Create the dataset instance
dataset_train = ToothDataset()
dataset_train.load_dataset(dataset_dir='Dental_Tooth_Classification', is_train=True)
dataset_train.prepare()

dataset_val = ToothDataset()
dataset_val.load_dataset(dataset_dir='Dental_Tooth_Classification', is_train=False)
dataset_val.prepare()

## Load the image and mask
image_id = dataset_train.image_ids[0]
image = dataset_train.load_image(image_id)
mask, class_ids = dataset_train.load_mask(image_id)



# Check the maximum class ID
print("Max class ID:", np.max(class_ids))
print("Number of classes:", len(dataset_train.class_names))
#tf.debugging.check_numerics(loss, "NaN detected in loss")




# Train the model

model.train(train_dataset=dataset_train, 
            val_dataset=dataset_val, 
            learning_rate=config.LEARNING_RATE, 
            epochs=10, 
            layers='heads')

# Save the model weights after training
model_path = "tooth_model2.h5"
model_dir = os.path.dirname(model_path)
if model_dir and not os.path.exists(model_dir):
    os.makedirs(model_dir)  # Ensure the directory exists
model.keras_model.save_weights(model_path)
print(f"Model weights saved to {model_path}")
